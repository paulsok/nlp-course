{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEQLNowBwQsg"
      },
      "source": [
        "# Homework: Transfer Learning & Domain Adaptation\n",
        "##  Named Entity Recognition\n",
        "\n",
        "Today we're gonna solve the problem of named entity recognition. Here's what it does in one picture:\n",
        "![img](https://commons.bmstu.wiki/images/0/00/NER1.png)\n",
        "[image source](https://bit.ly/2Pmg7L2)\n",
        "\n",
        "\n",
        "For each word, in a sentence, your model should predict a named entity class: _person, organization, location_ or _miscellaneous_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zYygbVI3taKX"
      },
      "source": [
        "## Data\n",
        "\n",
        "\n",
        "### Source domain testset\n",
        "\n",
        "Our train set consists from texts from different news sources. Therefore as source-domain testset we will use data from [CoNLL-2003 Shared Task](https://huggingface.co/datasets/conll2003). More information about the task can be found [here](https://www.clips.uantwerpen.be/conll2003/ner/).\n",
        "\n",
        "### Target domain (in-domain) data\n",
        "\n",
        "As target-domain data we will use data from [WNUT17 Emerging and Rare entity recognition task](http://noisy-text.github.io/2017/emerging-rare-entities.html). This shared task focuses on identifying unusual, previously-unseen entities in the context of emerging discussions. The data were mined from mined from Twitter, Reddit,\n",
        "YouTube and StackExchange. Results of different competitors of the task were published [here](https://noisy-text.github.io/2017/pdf/WNUT18.pdf).\n",
        "\n",
        "### Named entity classes\n",
        "\n",
        "* PER - _person_: names of people (e.g. Alexander S. Pushkin)\n",
        "* ORG - _organization_: names of corporations (e.g. Yandex), names of non-profit organizations (e.g. UNICEF)\n",
        "Google).\n",
        "* LOC - _location_ : e.g. Russia\n",
        "* MISC - _miscellaneous_ : other named entities including names of products (e.g. iPhone) and creative works (e.g. Bohemian Rhapsody)\n",
        "\n",
        "### Evaluation metrics\n",
        "\n",
        "As evaluation metrics we will F1 measure on exact matched NEs. It means that partially overlapped enitities of same class are considered as mismatch.\n",
        "For example, LOC entities below is partially overlapped. And it is a mismatch:\n",
        "\n",
        "__O, B-LOC, I-LOC, O__\n",
        "\n",
        "__O, B-LOC, I-LOC, I-LOC__\n",
        "\n",
        "Details can be found in the code of _conlleval.py_\n",
        "\n",
        "### Data format\n",
        "\n",
        "The format of all dataset follows popular [IOB format](https://en.wikipedia.org/wiki/Inside–outside–beginning_(tagging)). The B- prefix before a tag indicates that the tag is the beginning of a chunk, and an I- prefix before a tag indicates that the tag is inside a chunk. The B- tag is used only when a tag is followed by a tag of the same type without O tokens between them. An O tag indicates that a token belongs to no chunk.\n",
        "\n",
        "The named entity labels include:\n",
        "* __B-LOC__ - location - first token\n",
        "* __I-LOC__ - location - subsequent tokens\n",
        "* __B-ORG__ - organization - first token\n",
        "* __O__ - not a named entity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJHIk47HtaKY"
      },
      "source": [
        "### Part 1: dataset exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4hOsPCktaKY"
      },
      "source": [
        "To load datasets we will use `huggingface/datasets` library:\n",
        "\n",
        "https://huggingface.co/docs/datasets/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "n8C0yTzMuJX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNxDRGnAtaKZ"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "import typing as tp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRJbCRGPtaKa"
      },
      "outputs": [],
      "source": [
        "conll = datasets.load_dataset(\"conll2003\")\n",
        "wnut = datasets.load_dataset(\"wnut_17\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conll_test = conll[\"test\"]\n",
        "conll_train = conll[\"train\"]\n",
        "\n",
        "wnut_test = wnut[\"train\"]\n",
        "wnut_train = wnut[\"test\"]"
      ],
      "metadata": {
        "id": "AZqiK-KewUtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBgPBDBztaKa"
      },
      "source": [
        "This datasets is a actually `DatasetDict`s.\n",
        "\n",
        "_Hint_ : to see class hierarchy we can use `getmro` function from `inspect` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIJcnGXCtaKa"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "inspect.getmro(type(conll))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1BkR6ictaKb"
      },
      "outputs": [],
      "source": [
        "print(conll.keys(), wnut.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VTMPxsNtaKb"
      },
      "source": [
        "Let's have a look at content of test part CONLL dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QcSpvCttaKb"
      },
      "outputs": [],
      "source": [
        "conll[\"test\"].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVV1_K01taKb"
      },
      "outputs": [],
      "source": [
        "conll[\"test\"].dataset_size, len(conll[\"test\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BPs5wChitaKb"
      },
      "source": [
        "Let's have a look at single example in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BztbUIdvtaKb"
      },
      "outputs": [],
      "source": [
        "conll[\"test\"][50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-Uk5PZmtaKc"
      },
      "outputs": [],
      "source": [
        "# let's view available tags\n",
        "CONLL_NER_TAGS = conll['train'].features['ner_tags'].feature.names\n",
        "print(CONLL_NER_TAGS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7tcnol2taKc"
      },
      "source": [
        "Let's have a look at content of test part WNUT dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PEaGfmTktaKc"
      },
      "outputs": [],
      "source": [
        "wnut['test'].features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9_lwHYKItaKc"
      },
      "outputs": [],
      "source": [
        "wnut[\"test\"].dataset_size, len(wnut[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAkFfD6mtaKc"
      },
      "outputs": [],
      "source": [
        "print(wnut[\"test\"][50])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TI1kcVzktaKc"
      },
      "outputs": [],
      "source": [
        "WNUT_NER_TAGS = wnut['train'].features['ner_tags'].feature.names\n",
        "print(WNUT_NER_TAGS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V0JctrNtaKd"
      },
      "source": [
        "There is a fancy visualizer in `spacy` nlp library we can adapt for custom dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZJwh818taKd"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3x2elQkvtaKd"
      },
      "outputs": [],
      "source": [
        "def ner_render(tokens: tp.Sequence[str], ner_tags: tp.Sequence[str],\n",
        "               tags_list=CONLL_NER_TAGS, title: tp.Optional[str] = None, **kwargs):\n",
        "    pos = 0\n",
        "    ents = []\n",
        "    for word, tag_ in zip(tokens, ner_tags):\n",
        "        tag = tags_list[tag_]\n",
        "        if tag.startswith('B'):\n",
        "            ents.append({\n",
        "                \"start\": pos,\n",
        "                \"end\": pos + len(word),\n",
        "                \"label\": tag.split(\"-\")[1]\n",
        "            })\n",
        "        elif tag.startswith('I'):\n",
        "            ents[-1][\"end\"] = pos + len(word)\n",
        "        pos += (len(word) + 1)\n",
        "    displacy.render({\n",
        "        \"text\": \" \".join(tokens),\n",
        "        \"ents\": ents,\n",
        "        \"title\": title\n",
        "    }, style=\"ent\", manual=True, jupyter=True)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCQzW-GotaKd"
      },
      "source": [
        "Voilà!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uESrJglitaKd"
      },
      "outputs": [],
      "source": [
        "conll[\"test\"][50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbFsqvjhtaKd"
      },
      "outputs": [],
      "source": [
        "for test_id in [50, 200]:\n",
        "    ner_render(**conll[\"test\"][test_id], tags_list=CONLL_NER_TAGS, title = f'conll[{test_id}]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8O2BKrqbtaKe"
      },
      "outputs": [],
      "source": [
        "for test_id in [100, 142]:\n",
        "    ner_render(**wnut[\"test\"][test_id], tags_list=WNUT_NER_TAGS, title = f'wnut[{test_id}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wwwS5p1XtaKe"
      },
      "source": [
        "Let's compare CONLL and WNUT named entity tags. We need to count each type of tags in both datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3tWkkxqtaKe"
      },
      "outputs": [],
      "source": [
        "from itertools import chain\n",
        "from collections import Counter\n",
        "\n",
        "# Count every type of tag in CONLL and WNUT datasets:\n",
        "\n",
        "conll_tag_counts = Counter()\n",
        "wnut_tag_counts = Counter()\n",
        "\n",
        "for tags in conll_test[\"ner_tags\"]:\n",
        "  conll_tag_counts.update(tags)\n",
        "\n",
        "for tags in wnut_test[\"ner_tags\"]:\n",
        "  wnut_tag_counts.update(tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81CVVfTntaKe"
      },
      "outputs": [],
      "source": [
        "wnut_tag_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OIM-96HGtaKe"
      },
      "outputs": [],
      "source": [
        "conll_tag_counts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Saw6crIrtaKe"
      },
      "source": [
        "Thus, WNUT and CONLL have different set of NE tags (labels)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85i8kwhltaKf"
      },
      "source": [
        "From WNUT description:\n",
        "\n",
        "**person** –  Names  of  people  (e.g.Virginia Wade).   Don’t mark people that don’t have their own name.  Include punctuation in the middle ofnames.  Fictional people can be included, as long as they’re referred to by name (e.g.Harry Potter).\n",
        "\n",
        "**location** –  Names  that  are  locations  (e.g. France).    Don’t  mark  locations  that  don’t  have their own name.  Include punctuation in the middle of names. Fictional locations can be included, as long as they’re referred to by name (e.g.Hogwarts)\n",
        "\n",
        "**corporation** –  Names  of  corporations  (e.g.Google).   Don’t  mark  locations  that  don’t  have their own name. Include punctuation in the middle of names\n",
        "\n",
        "**product** –  Name  of  products  (e.g. iPhone). Don’t  mark  products  that  don’t  have  their  own name. Include punctuation in the middle of names. Fictional  products  can  be  included,  as  long  as they’re referred to by name (e.g.Everlasting Gobstopper).  It’s got to be something you can touch, and it’s got to be the official name.\n",
        "\n",
        "**creative-work** –  Names  of  creative  works (e.g.Bohemian Rhapsody). Include punctuation inthe middle of names. The work should be created by a human, and referred to by its specific name.\n",
        "\n",
        "**group** – Names of groups (e.g.Nirvana, SanDiego  Padres). Don’t  mark  groups  that  don’t have a specific, unique name, or companies (which should be marked corporation).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hH3_c7nqtaKf"
      },
      "source": [
        "We can match CONLL and WNUT labels and label indices using next rules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zvm22HEYtaKf"
      },
      "outputs": [],
      "source": [
        "label_mapping = {\n",
        "    'O': 'O',\n",
        "    'B-location': 'B-LOC',\n",
        "    'I-location': 'I-LOC',\n",
        "    'B-group': 'B-ORG',\n",
        "    'B-corporation': 'B-ORG',\n",
        "    'B-person': 'B-PER',\n",
        "    'B-creative-work': 'B-MISC',\n",
        "    'B-product': 'B-MISC',\n",
        "    'I-person': 'I-PER',\n",
        "    'I-creative-work': 'I-MISC',\n",
        "    'I-corporation': 'I-ORG',\n",
        "    'I-group': 'I-ORG',\n",
        "    'I-product': 'I-MISC'\n",
        "}\n",
        "\n",
        "labelindexmapping = {WNUT_NER_TAGS.index(k):CONLL_NER_TAGS.index(v) for k, v in label_mapping.items()}\n",
        "print(labelindexmapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pIEH-uy8taKg"
      },
      "outputs": [],
      "source": [
        "def convert_label_sequence(example: tp.Dict[str, tp.Any], label_mapping: tp.Dict[str, str]) -> tp.Dict[str, tp.Any]:\n",
        "    converted_example = dict(**example)\n",
        "    converted_example['ner_tags'] = [label_mapping[label] for label in example['ner_tags']]\n",
        "    return converted_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y4X9iTKMtaKg"
      },
      "outputs": [],
      "source": [
        "converted_wnut = wnut.map(lambda x: convert_label_sequence(x, labelindexmapping))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DfoiJm8taKg"
      },
      "source": [
        "**Before:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_MQ2GoTtaKg"
      },
      "outputs": [],
      "source": [
        "for i in [1, 2, 3]:\n",
        "    ner_render(**wnut[\"train\"][i], tags_list=WNUT_NER_TAGS, title = f'wnut_train_[{i}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EF2x70ULtaKh"
      },
      "source": [
        "**After label mapping:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5a_q1nztaKh"
      },
      "outputs": [],
      "source": [
        "for i in [1, 2, 3]:\n",
        "    ner_render(**converted_wnut[\"train\"][i], tags_list=CONLL_NER_TAGS,\n",
        "               title = f'converted_wnut_train_[{i}]')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIl1pRintaKi"
      },
      "source": [
        "To visualize lexical differences between WNUT and CONLL let's use `scattertext` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRRp63intaKi"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML, IFrame\n",
        "HTML(\"<style>.container { width:98% !important; }</style>\")\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjcyn571taKi"
      },
      "outputs": [],
      "source": [
        "!pip3 install scattertext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ht9TxXFBtaKj"
      },
      "outputs": [],
      "source": [
        "import scattertext as st\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GbjrkhgMtaKj"
      },
      "outputs": [],
      "source": [
        "conll_df = pd.DataFrame([{\"text\": \" \".join(example[\"tokens\"]), \"ner\": example[\"ner_tags\"], \"dataset\": \"conll\"} for example in conll[\"train\"]])\n",
        "wnut_df = pd.DataFrame([{\"text\": \" \".join(example[\"tokens\"]), \"ner\": example[\"ner_tags\"], \"dataset\": \"wnut\"} for example in converted_wnut[\"train\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQc35RmZtaKj"
      },
      "outputs": [],
      "source": [
        "df = pd.concat([conll_df, wnut_df])\n",
        "df['parse'] = df.text.apply(st.whitespace_nlp_with_sentences)\n",
        "\n",
        "corpus = st.CorpusFromParsedDocuments(df, category_col='dataset', parsed_col='parse') \\\n",
        "    .build().get_unigram_corpus().compact(st.AssociationCompactor(2000))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LJga-2xtaKj"
      },
      "outputs": [],
      "source": [
        "with pd.option_context('mode.chained_assignment', None):\n",
        "    # scattertext has pd.SettingWithCopyWarning in ScatterChart._add_term_freq_to_json_df\n",
        "    html = st.produce_scattertext_explorer(\n",
        "        corpus,\n",
        "        category='conll', category_name='CONLL', not_category_name='WNUT',\n",
        "        minimum_term_frequency=0, pmi_threshold_coefficient=0,\n",
        "        width_in_pixels=1000,\n",
        "        transform=st.Scalers.dense_rank\n",
        "    )\n",
        "\n",
        "with open(\"difference.html\", \"w\") as outf:\n",
        "    print(html, file=outf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad2V1PwetaKj"
      },
      "outputs": [],
      "source": [
        "IFrame(\"difference.html\", width=1200, height=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2N2xy_TGtaKj"
      },
      "source": [
        "### Part 2: BERT sequence labeling recap (2 points)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehxlwA7MtaKj"
      },
      "source": [
        "https://huggingface.co/transformers/task_summary.html#named-entity-recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTY35xiWtaKj"
      },
      "source": [
        "The sequence labeling task is a degenerate case of the seq2seq task: we need to map a sequence of words to a sequence of labels (tags) of **the same length**.\n",
        "\n",
        "In case of BERT we want to get a vector of probabilities of labels for each input token. The simplest way to make it is just feed output token embeddings to Linear layer.\n",
        "\n",
        "`transformers` class `BertForTokenClassification` works just like this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sV3DgkWUtaKj"
      },
      "source": [
        "![image.png](attachment:image.png)\n",
        "\n",
        "Image from FastAI article: https://d2l.ai/chapter_natural-language-processing-applications/finetuning-bert.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qt5yJ_1ItaKj"
      },
      "source": [
        "#### 2.1 Load pre-trained BERT-based sequence tagger"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "g6du4RgpxfEU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rS6C4T6BtaKk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import sklearn\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "from tqdm.auto import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZocJEp3taKk"
      },
      "outputs": [],
      "source": [
        "from transformers import (pipeline,\n",
        "        AutoModelForTokenClassification, AutoTokenizer,\n",
        "        BertForTokenClassification, BertTokenizer)\n",
        "\n",
        "\n",
        "name = \"dslim/bert-base-NER\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hf3D3rmftaKk"
      },
      "source": [
        "Let's have a look at `BertForTokenClassification` class hierarchy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfOr2ohVtaKk"
      },
      "outputs": [],
      "source": [
        "inspect.getmro(type(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D432SsnvtaKk"
      },
      "source": [
        "In `transformers.BertPreTrainedModel` there is an important attribute `config`. Let's have a look."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRtfxAI8taKk"
      },
      "outputs": [],
      "source": [
        "model.config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BScJxnStaKk"
      },
      "source": [
        "As mentioned above `BertForTokenClassification` = BERT + linear classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "PNOjErCwtaKk"
      },
      "outputs": [],
      "source": [
        "model.classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MrkCHMataKk"
      },
      "outputs": [],
      "source": [
        "model.bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPJh2U3ktaKk"
      },
      "source": [
        "Let's explore one example from dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gIj1HC0qtaKk"
      },
      "outputs": [],
      "source": [
        "ner_render(**conll[\"test\"][10], tags_list=CONLL_NER_TAGS)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzxrdqTZtaKk"
      },
      "source": [
        "Tokenizer call splits sequence of words to sequnce of word pieces (bpe units) and maps it to token ids."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JMKoAymqtaKk"
      },
      "outputs": [],
      "source": [
        "encoded = tokenizer(conll[\"test\"][10][\"tokens\"], is_split_into_words=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btl1u07NtaKl"
      },
      "outputs": [],
      "source": [
        "encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPWHYE6-taKl"
      },
      "source": [
        "Here:\n",
        "\n",
        "`input_ids` - indices of input sequence tokens in the vocabulary\n",
        "\n",
        "`token_type_ids` - segment token indices to indicate first and second portions of the inputs. Indices are selected in [0, 1]: 0 corresponds to a sentence A token, 1 corresponds to a sentence B token\n",
        "\n",
        "`attention_mask` - mask to avoid performing attention on padding token indices. Mask values selected in [0, 1]:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6s1pd09taKl"
      },
      "source": [
        "As we discussed above in sequence labeling task output sequence length should be equal to input sequence length.\n",
        "\n",
        "Tokenizer can split single world to multiple pieces:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pr9pEcnetaKl"
      },
      "outputs": [],
      "source": [
        "print(f\"Original sentence:\\n---\\n{' '.join(conll['test'][10]['tokens'])}\")\n",
        "\n",
        "tokenized = \" \".join([tokenizer.convert_ids_to_tokens(id_) for id_ in encoded[\"input_ids\"]])\n",
        "print(f\"\\nTokenized sentence:\\n---\\n{tokenized}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CF5nIJIFtaKl"
      },
      "source": [
        "For example named entity `Takuya Takagi` transforms into `Ta ##ku ##ya Ta ##ka ##gi`. We need to preserve invariant: input sequence length = output sequence length. So sequence labels (tags) should be tokenized too.\n",
        "\n",
        "\n",
        "```\n",
        "Takuya Takagi -> Ta    ##ku   ##ya   Ta     ##ka    ##gi\n",
        "   |     |        |     |       |     |      |        |\n",
        "B-PER  I-PER    B-PER  I-PER  I-PER  I-PER  I-PER   I-PER\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-uaq6yrtaKl"
      },
      "source": [
        "Let's write function for it."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "-BXdoosLxoJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MGTpWrvtaKl"
      },
      "outputs": [],
      "source": [
        "def tokenize_and_preserve_tags(example: tp.Dict[str, tp.Any],\n",
        "                               model,\n",
        "                               tokenizer: transformers.BertTokenizer,\n",
        "                               label2id: tp.Dict[str, int],\n",
        "                               tokenizer_params={}) -> tp.Dict[str, tp.Any]:\n",
        "    # function to split each pair of word-token to same number of pieces.\n",
        "    encoded = tokenizer(example[\"tokens\"], is_split_into_words=True, **tokenizer_params)\n",
        "    encoded.update(example)\n",
        "\n",
        "    word_ids = encoded.word_ids()\n",
        "    text_labels = []\n",
        "    for i in range(1, len(word_ids) - 1):\n",
        "        label = example[\"ner_tags\"][word_ids[i]]\n",
        "        if isinstance(label, int):\n",
        "            label = model.config.id2label[label]\n",
        "        if label == \"O\" or word_ids[i - 1] != word_ids[i]:\n",
        "            text_labels.append(label)\n",
        "        else:\n",
        "            text_labels.append(\"I\" + label[1:])\n",
        "    text_labels = [\"O\"] + text_labels + [\"O\"]\n",
        "\n",
        "    for key in ['input_ids', 'attention_mask', 'token_type_ids']:\n",
        "        encoded[key] = torch.tensor(encoded[key])\n",
        "\n",
        "    encoded['labels'] = [label2id[label] for label in text_labels]\n",
        "    encoded['text_labels'] = text_labels\n",
        "\n",
        "    assert len(encoded['labels']) == len(encoded[\"input_ids\"])\n",
        "    return encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o1fj4RuLtaKl"
      },
      "outputs": [],
      "source": [
        "test_sentence = \"His name is Jerry Abrahamson\"\n",
        "test_example = {\"tokens\": test_sentence.split(\" \"), \"ner_tags\": [\"O\", \"O\", \"O\", \"B-PER\", \"I-PER\"]}\n",
        "test_result = tokenize_and_preserve_tags(test_example, model, tokenizer, model.config.label2id)\n",
        "\n",
        "assert tokenizer.decode(test_result['input_ids']) == '[CLS] His name is Jerry Abrahamson [SEP]'\n",
        "\n",
        "                                     #CLS     His  name is    Jerry    Abraham   ##son      SEP\n",
        "assert test_result['text_labels'] == [\"O\"] + [\"O\", \"O\", \"O\", \"B-PER\", \"I-PER\",  \"I-PER\"] + [\"O\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e7Qy1mC0taKl"
      },
      "outputs": [],
      "source": [
        "conll = conll.map(lambda x: tokenize_and_preserve_tags(x, model, tokenizer, model.config.label2id))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BN1lYpntaKl"
      },
      "outputs": [],
      "source": [
        "wnut = converted_wnut\n",
        "wnut = wnut.map(lambda x: tokenize_and_preserve_tags(x, model, tokenizer, model.config.label2id))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbMRaAvmtaKl"
      },
      "source": [
        "Next step is convert all numpy.arrays to torch.tensors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIkezwALtaKl"
      },
      "outputs": [],
      "source": [
        "conll.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'], output_all_columns=True)\n",
        "wnut.set_format(type='torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'], output_all_columns=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAM9jjLLtaKl"
      },
      "outputs": [],
      "source": [
        "conll[\"test\"][:1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeB1tjRDtaKm"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Qu-SKebtaKm"
      },
      "source": [
        "To use `transformers.Dataset` with `torch.DataLoader` we need a custom function to pad sequences and make batches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qCg91bPtaKm"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "class PadSequence:\n",
        "    def __init__(self, padded_columns, device='cuda'):\n",
        "        self.padded_columns = set(padded_columns)\n",
        "        self.device = device\n",
        "\n",
        "    def __call__(self, batch):\n",
        "        padded_batch = defaultdict(list)\n",
        "        for example in batch:\n",
        "            for key, tensor in example.items():\n",
        "                padded_batch[key].append(tensor)\n",
        "\n",
        "        for key, val in padded_batch.items():\n",
        "            if key in self.padded_columns:\n",
        "                padded_batch[key] = torch.nn.utils.rnn.pad_sequence(val, batch_first=True).to(self.device)\n",
        "        return padded_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jR7kV2otaKm"
      },
      "outputs": [],
      "source": [
        "conll_test_dataloader = torch.utils.data.DataLoader(conll[\"test\"], batch_size=4, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta8_j9nWtaKm"
      },
      "source": [
        "Let's test it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2p4UZg_7taKm"
      },
      "outputs": [],
      "source": [
        "test_batch = next(iter(conll_test_dataloader))\n",
        "model_output = model(input_ids=test_batch[\"input_ids\"],\n",
        "                     token_type_ids=test_batch[\"token_type_ids\"],\n",
        "                     attention_mask=test_batch[\"attention_mask\"],\n",
        "                     labels=test_batch[\"labels\"], return_dict=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_tbBcOCstaKm"
      },
      "outputs": [],
      "source": [
        "model_output.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1BuGFZ2taKm"
      },
      "source": [
        "Model output contains only `loss` and `logits`. We need to write simple wrapper to convert raw logits to token sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NmjuB7ftaKm"
      },
      "outputs": [],
      "source": [
        "class NamedEntityPredictor:\n",
        "    def __init__(self,\n",
        "                 model: transformers.BertForTokenClassification,\n",
        "                 tokenizer: transformers.BertTokenizer,\n",
        "                 id2label: tp.Optional[tp.Dict[str, int]] = None):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "        self.id2label = model.config.id2label if id2label is None else id2label\n",
        "\n",
        "    def predict(self, batch: tp.Dict[str, tp.Any]):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            model_output = self.model(input_ids=batch[\"input_ids\"],\n",
        "                                      token_type_ids=batch[\"token_type_ids\"],\n",
        "                                      attention_mask=batch[\"attention_mask\"],\n",
        "                                      labels=batch[\"labels\"],\n",
        "                                      return_dict=True)\n",
        "        indices = torch.argmax(model_output.logits, axis=2)\n",
        "        indices = indices.detach().cpu().numpy()\n",
        "\n",
        "        attention_mask = batch[\"attention_mask\"].cpu().numpy()\n",
        "        batch_size = len(batch[\"input_ids\"])\n",
        "        predicted_labels = []\n",
        "        for i in range(batch_size):\n",
        "            predicted_labels.append([self.id2label[id_] for id_ in indices[i][attention_mask[i] == 1]])\n",
        "\n",
        "        return {\n",
        "            \"predicted_labels\": predicted_labels,\n",
        "            \"loss\": model_output.loss,\n",
        "            \"logits\": model_output.logits\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbhIGFBHtaKm"
      },
      "outputs": [],
      "source": [
        "ner = NamedEntityPredictor(model, tokenizer)\n",
        "test_prediction = ner.predict(test_batch)\n",
        "assert test_prediction['predicted_labels'][2] == list(test_batch[\"text_labels\"][2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rVxM62ujtaKm"
      },
      "source": [
        "Let's measure quality of NER for in-domain and out-domain testset.\n",
        "\n",
        "To compare models we can use F1 measure. There is a great package `seqeval` to make such quality measurements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9K03-eQQtaKm"
      },
      "outputs": [],
      "source": [
        "!pip3 install seqeval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQYTsL2xtaKm"
      },
      "outputs": [],
      "source": [
        "conll_test_dataloader = torch.utils.data.DataLoader(conll[\"test\"], batch_size=16, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))\n",
        "wnut_test_dataloader = torch.utils.data.DataLoader(wnut[\"test\"], batch_size=16, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPYJTDAitaKm"
      },
      "outputs": [],
      "source": [
        "ner = NamedEntityPredictor(model, tokenizer)\n",
        "predicted_labels = {\"wnut_test\": [], \"conll_test\": []}\n",
        "\n",
        "for batch in tqdm(conll_test_dataloader):\n",
        "    predicted_labels[\"conll_test\"].extend(ner.predict(batch)[\"predicted_labels\"])\n",
        "\n",
        "for batch in tqdm(wnut_test_dataloader):\n",
        "    predicted_labels[\"wnut_test\"].extend(ner.predict(batch)[\"predicted_labels\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install seqeval"
      ],
      "metadata": {
        "id": "tAedKvzO0e4g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKxD-elhtaKm"
      },
      "outputs": [],
      "source": [
        "from seqeval.metrics import classification_report, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9by8JlwdtaKn"
      },
      "outputs": [],
      "source": [
        "conll_report = classification_report(y_true=[list(example[\"text_labels\"]) for example in conll[\"test\"]],\n",
        "                                                     y_pred=predicted_labels[\"conll_test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9orzYeEtaKn"
      },
      "outputs": [],
      "source": [
        "wnut_report = classification_report(y_true=[list(example[\"text_labels\"]) for example in wnut[\"test\"]],\n",
        "                                                    y_pred=predicted_labels[\"wnut_test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QrLiv-2_taKn"
      },
      "outputs": [],
      "source": [
        "print(f\"CONLL:\\n {conll_report}\")\n",
        "print(f\"WNUT:\\n {wnut_report}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErM01Z9etaKn"
      },
      "source": [
        "As we can see WNUT model perfomance is poor. Let's test hypothesis that for CONLL-like inputs NER quality will be higher.\n",
        "\n",
        "To make this we will train a simple log-regression to classify sentences between two datasets based on their sentence embeddings.\n",
        "\n",
        "The sentence embeddings can be obtained from [CLS] token embedding.\n",
        "\n",
        "For classification we will train vanilla sklearn log-regression. Just like on picture below, but we will use ordinary BERT for sentence embeddings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PT_2oiStaKn"
      },
      "source": [
        "![image.png](attachment:image.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zO7pwbItaKn"
      },
      "source": [
        "Picture from great [Jay Alammar's blog post](http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ4HisSOtaKn"
      },
      "outputs": [],
      "source": [
        "def get_sentence_embeddings(model, batch):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        return model.bert(input_ids=batch[\"input_ids\"],\n",
        "                          token_type_ids=batch[\"token_type_ids\"],\n",
        "                          attention_mask=batch[\"attention_mask\"],\n",
        "                          return_dict=True)[\"last_hidden_state\"].cpu().numpy()[:,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "eGDTGtzYtaKn"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "Y = []\n",
        "\n",
        "conll_train_dataloader = torch.utils.data.DataLoader(conll[\"train\"], batch_size=32, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))\n",
        "wnut_train_dataloader = torch.utils.data.DataLoader(wnut[\"train\"], batch_size=32, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))\n",
        "\n",
        "for batch in tqdm(conll_train_dataloader):\n",
        "    X.append(get_sentence_embeddings(model, batch))\n",
        "    Y.extend([0] * len(batch[\"input_ids\"]))\n",
        "\n",
        "for batch in tqdm(wnut_train_dataloader):\n",
        "    X.append(get_sentence_embeddings(model, batch))\n",
        "    Y.extend([1] * len(batch[\"input_ids\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0Nvdcb8taKo"
      },
      "outputs": [],
      "source": [
        "X = np.concatenate(X)\n",
        "Y = np.array(Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cz4p3_motaKo"
      },
      "outputs": [],
      "source": [
        "dataset_classifier = sklearn.linear_model.LogisticRegression(max_iter=1000)\n",
        "dataset_classifier.fit(X, Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9CsNZHqtaKo"
      },
      "outputs": [],
      "source": [
        "wnut_test_scores = []\n",
        "\n",
        "wnut_test_dataloader = torch.utils.data.DataLoader(wnut[\"test\"], batch_size=32, collate_fn=PadSequence(['input_ids', 'token_type_ids', 'attention_mask', 'labels']))\n",
        "for batch in tqdm(wnut_test_dataloader):\n",
        "    x = get_sentence_embeddings(model, batch)\n",
        "    wnut_test_scores.append(dataset_classifier.predict_proba(x)[:,1])\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owtPO9VltaKo"
      },
      "outputs": [],
      "source": [
        "wnut_test_scores = np.concatenate(wnut_test_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDyw6r6wtaKo"
      },
      "outputs": [],
      "source": [
        "plt.hist(wnut_test_scores)\n",
        "plt.xlabel(\"WNUT score.\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAqTRow9taKo"
      },
      "outputs": [],
      "source": [
        "score_indices = np.argsort(wnut_test_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTNo9fnLtaKo"
      },
      "outputs": [],
      "source": [
        "wnut_predicted_labels = np.array(predicted_labels[\"wnut_test\"], dtype=object\n",
        "                                )[np.argsort(wnut_test_scores)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBzoJnM6taKo"
      },
      "outputs": [],
      "source": [
        "wnut_true_labels = np.array([list(example[\"text_labels\"]) for example in wnut[\"test\"]], dtype=object\n",
        "                           )[np.argsort(wnut_test_scores)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCXZnFhdtaKo"
      },
      "source": [
        "After sorting true and predicted labels based on WNUT score let split them into 5 chunks and measure F1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZjbPtextaKo"
      },
      "outputs": [],
      "source": [
        "predicted_splits = np.array_split(wnut_predicted_labels, 5, )\n",
        "true_splits = np.array_split(wnut_true_labels, 5)\n",
        "score_splits = np.array_split(wnut_test_scores[np.argsort(wnut_test_scores)], 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRusXSBrtaKp"
      },
      "outputs": [],
      "source": [
        "print(\"score\\tf1\")\n",
        "for scores, true_split, predicted_split in zip(score_splits, true_splits, predicted_splits):\n",
        "    mean_score = np.mean(scores)\n",
        "    f1 = f1_score(true_split, predicted_split)\n",
        "    print(f\"{mean_score:.3f}\\t{f1:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnYX6brmtaKp"
      },
      "source": [
        "So:\n",
        "\n",
        "**The bigger domain shift the lower f1 measure**"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}